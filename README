

---

# ğŸ“Š Transaction Importer & Analytics Pipeline

A production-grade data engineering pipeline designed to handle high-frequency ingestion of financial transactions. It utilizes a **Hybrid Storage Strategy**: leveraging **Redis** for sub-millisecond real-time aggregation and **MongoDB** for reliable, long-term historical persistence.

## âœ¨ Features

### âš¡ High-Speed Ingestion

* **O(1) Aggregation** - Uses Redis `HINCRBYFLOAT` for sub-millisecond real-time daily totals.
* **Asynchronous Processing** - Decouples data ingestion from persistence using Redis lists as a high-speed message broker.
* **Bulk Persistence** - Minimizes MongoDB I/O overhead by grouping thousands of transactions into consolidated daily summaries via the background worker.

### ğŸ› ï¸ Background Archiving

* **Automated Sync** - A dedicated worker service monitors the "hot" Redis cache and persists data to MongoDB every 10 seconds.
* **Smart Cleanup** - Automatically purges Redis keys older than 7 days to maintain a lean memory footprint.
* **Resilient Design** - Uses `asyncio` error handling to ensure the sync loop remains alive during network blips or database restarts.

### ğŸ³ Infrastructure

* **Service Separation** - Multi-container setup separating HTTP (API), Background Worker, Cache (Redis), and Database (MongoDB).
* **Deterministic Environments** - Built with Docker and Pipenv (`Pipfile.lock`) to ensure "it works on my machine" translates to "it works in production."

## ğŸ—ï¸ System Architecture

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP POST      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Importer  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   FastAPI App    â”‚
â”‚  (Python Script)â”‚                     â”‚   (Port: 8080)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â”‚ Push to Queue
                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Sync & Cleanup   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MongoDB Store  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Python Worker   â”‚
â”‚ (Port: 27017)   â”‚      (10s Loop)     â”‚ (Asyncio/Motor)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â”‚ Aggregate
                                                 â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚   Redis Cache    â”‚
                                        â”‚   (Port: 6379)   â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸ“¦ Tech Stack

| Component | Technology |
| --- | --- |
| **Backend Framework** | FastAPI (Python 3.12) |
| **Task Queue** | Redis (List-based Queue) |
| **Real-time Store** | Redis (Hashes for Daily Stats) |
| **Historical DB** | MongoDB (Document Store) |
| **Database Drivers** | Motor (Async MongoDB), Redis-py |
| **Containerization** | Docker, Docker Compose |
| **Package Management** | Pipenv (Pipfile) |

## ğŸ“ Project Structure

```text
FastAPI_transaction_importer/:
â”œâ”€â”€ docker-compose.yml       # Infrastructure orchestration
â”œâ”€â”€ Dockerfile               # Container definition
â”œâ”€â”€ main.py                  # FastAPI Entry point
â”œâ”€â”€ worker.py                # Async Sync & Cleanup Loop
â”œâ”€â”€ database.py              # MongoDB/Motor configuration
â”œâ”€â”€ redis_client.py          # Redis connection logic
â”œâ”€â”€ models.py                # Data schemas
â”œâ”€â”€ importer.py              # CSV processing script
â”œâ”€â”€ transactions_1_month.csv # Sample dataset
â”œâ”€â”€ Pipfile                  # Dependency management
â””â”€â”€ .gitignore               # Version control exclusions

```

## ğŸš€ Quick Start (Local Deployment)

### 1. Installation

```bash
# Clone the repository 
git clone https://github.com/lamaDayoub/FastAPI_transaction_importer
cd FastAPI_transaction_importer

# Initialize environment (Optional)
cp .env.example .env

```

### 2. Launch Services

Build and start all microservices in detached mode. This triggers the API and the Background Worker automatically.

```bash
docker-compose up --build -d

```



## ğŸ” Monitoring & API

### Watch Live Sync Logs

Monitor the worker's heartbeat as it persists data from Redis to MongoDB:

```bash
docker logs -f transaction_importer-worker-1

```

### Database Verification

**Check MongoDB Collections:**

```bash
docker exec -it transaction_importer-mongodb-1 mongosh --eval "db.getSiblingDB('transaction_db').getCollectionNames()"

```

**Check API Documentation:**
Access the auto-generated Swagger UI to test endpoints:
`http://localhost:8080/docs`

## ğŸ³ Docker Service Mapping

| Service | Container Port | Host Port | Description |
| --- | --- | --- | --- |
| `app` | 8000 | **8080** | FastAPI REST API |
| `worker` | -- | -- | Background Sync & Cleanup |
| `mongodb` | 27017 | **27017** | Permanent Document Store |
| `redis` | 6379 | **6379** | Message Broker & Cache |

---

