

# ğŸ“Š Transaction Importer & Analytics Pipeline

A high-performance data engineering pipeline designed to ingest, aggregate, and persist 5,000 financial transactions using a **Hybrid Storage Strategy**. Built with FastAPI, Redis, and MongoDB.

## âœ¨ Features

### âš¡ High-Speed Ingestion

* **O(1) Aggregation**: Uses Redis `HINCRBYFLOAT` for sub-millisecond real-time daily totals.
* **Asynchronous Producer/Consumer**: Decouples data ingestion from database persistence using Redis lists as a message broker.
* **Bulk Upserts**: Minimizes MongoDB overhead by grouping thousands of transactions into consolidated daily summaries.

### ğŸ› ï¸ Background Processing

* **Automated Archiving**: A dedicated worker service monitors the "hot" Redis cache and persists data to MongoDB every 10 seconds.
* **Smart Cleanup**: Automatically purges Redis keys older than 7 days to maintain a lean memory footprint.
* **Fault Tolerance**: Implements `asyncio` error handling to ensure the sync loop remains alive during network blips.

### ğŸ³ Production Ready

* **Dockerized Microservices**: Separated services for API, Worker, Cache, and Database.
* **Live Observability**: Real-time logging of synchronization metrics and persistence counts.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      HTTP POST      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CSV Importer  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚   FastAPI App    â”‚
â”‚  (Python Script)â”‚                     â”‚   (Port: 8080)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â”‚ Push to Queue
                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    Sync & Cleanup   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  MongoDB Store  â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Python Worker   â”‚
â”‚ (Port: 27017)   â”‚      (10s Loop)     â”‚ (Asyncio/Motor)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                                 â”‚ Aggregate
                                                 â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚   Redis Cache    â”‚
                                        â”‚   (Port: 6379)   â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

## ğŸ“¦ Tech Stack

| Component | Technology |
| --- | --- |
| **Backend** | FastAPI, Python 3.10+ |
| **Task Queue** | Redis (List-based Queue) |
| **Real-time Store** | Redis (Hashes for Daily Stats) |
| **Historical DB** | MongoDB (Document Store) |
| **Concurrency** | Asyncio, Motor (Async Mongo Driver) |
| **Orchestration** | Docker, Docker Compose |

## ğŸš€ Quick Start (Local Deployment)

### 1. Clone & Setup

```bash
# Clone the repository
git clone https://github.com/lamaDayoub/transaction_importer.git
cd transaction_importer

# Initialize environment (Optional)
cp .env.example .env

```

### 2. Launch Infrastructure

Start all microservices in detached mode. This automatically triggers the Background Worker.

```bash
docker-compose up --build -d

```



## ğŸ” Monitoring & Validation

### Live Sync Logs

Watch the Worker perform real-time persistence and cleanup:

```bash
docker logs -f transaction_importer-worker-1

```

### Database Verification

**Check MongoDB Collection:**

```bash
docker exec -it transaction_importer-mongodb-1 mongosh --eval "db.getSiblingDB('transaction_db').getCollectionNames()"


```

**Check API Stats:**
Access the auto-generated Swagger UI: `http://localhost:8080/docs`

## ğŸ“ Project Structure

```text
transaction_importer/
â”œâ”€â”€ docker-compose.yml       # Infrastructure orchestration
â”œâ”€â”€ Dockerfile               # Container definition
â”œâ”€â”€ main.py                  # FastAPI Entry point
â”œâ”€â”€ worker.py                # Async Sync & Cleanup Loop
â”œâ”€â”€ database.py              # MongoDB/Motor configuration
â”œâ”€â”€ redis_client.py          # Redis connection logic
â”œâ”€â”€ models.py                # Data schemas
â”œâ”€â”€ importer.py              # CSV processing script
â”œâ”€â”€ transactions_1_month.csv # Sample dataset
â”œâ”€â”€ Pipfile                  # Dependency management
â””â”€â”€ .gitignore               # Version control exclusions

```

## ğŸ› ï¸ Docker Services

| Service | Host Port | Description |
| --- | --- | --- |
| `app` | 8080 | FastAPI REST Interface |
| `worker` | -- | Background Sync & Redis Cleanup |
| `mongodb` | 27017 | Permanent Historical Storage |
| `redis` | 6379 | High-speed Queue & Aggregator |

---
